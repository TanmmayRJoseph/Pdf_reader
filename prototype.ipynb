{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T08:31:09.111432Z",
     "start_time": "2025-07-16T08:31:09.081842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "from typing import List, Optional\n",
    "from langchain.vectorstores import Chroma\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ],
   "id": "2fc1e0ad9d3c6562",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T08:31:09.133437Z",
     "start_time": "2025-07-16T08:31:09.122103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment variable\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Check and print status\n",
    "print(\"API key loaded successfully!\" if GOOGLE_API_KEY else \"API key not found!\")"
   ],
   "id": "e24c24dfb9afb346",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T08:31:09.198856Z",
     "start_time": "2025-07-16T08:31:09.152587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make sure to set the GOOGLE_API_KEY in your .env file\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash-latest\",\n",
    "    temperature=0.5,\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")\n",
    "# making sure llm is working add a print statement\n",
    "print(\"LLM initialized successfully!\")"
   ],
   "id": "694e839ff2f97932",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized successfully!\n"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T08:31:09.237623Z",
     "start_time": "2025-07-16T08:31:09.225037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class AgentState:\n",
    "    query: Optional[str] = None\n",
    "    retrieved_docs: Optional[List[Document]] = None\n",
    "    answer: Optional[str] = None"
   ],
   "id": "fe0644620548f4d0",
   "outputs": [],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T08:31:25.787872Z",
     "start_time": "2025-07-16T08:31:09.250164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#raissing an error if pdf is not found\n",
    "if not os.path.exists(\"data\"):\n",
    "    raise FileNotFoundError(\"The 'data' directory does not exist. Please create it and add your PDF files.\")\n",
    "\n",
    "# Setup embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "# Load all PDFs from folder\n",
    "pdf_dir = \"data\"\n",
    "all_pdf = []\n",
    "\n",
    "for filename in os.listdir(pdf_dir):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(os.path.join(pdf_dir, filename))\n",
    "        all_pdf.extend(loader.load())\n",
    "\n",
    "print(\"All PDFs loaded and parsed:\", len(all_pdf), \"documents.\")\n",
    "\n",
    "# Now split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(all_pdf)\n",
    "print(\"Chunks created:\", len(chunks))\n",
    "\n",
    "persist_directory = r\"C:\\Users\\Tanmmay R Joseph\\OneDrive\\Desktop\\RagAgent\"\n",
    "collection_name = \"rag_agent_test\"\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Vector DB created and persisted.\")\n",
    "\n",
    "# If our collection does not exist in the directory, we create using the os command\n",
    "if not os.path.exists(persist_directory):\n",
    "    os.makedirs(persist_directory)"
   ],
   "id": "b17c9662b60d6c0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All PDFs loaded and parsed: 37 documents.\n",
      "Chunks created: 192\n",
      "‚úÖ Vector DB created and persisted.\n"
     ]
    }
   ],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T08:31:25.804276Z",
     "start_time": "2025-07-16T08:31:25.798933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# defining input and updating the query\n",
    "def input_node(s: AgentState):\n",
    "    \"\"\" This function prompts the user for a question and updates the state with the query.\"\"\"\n",
    "    s.query = input(\"What is your question? \")\n",
    "    return s"
   ],
   "id": "e920402ae9674c69",
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T08:31:25.824120Z",
     "start_time": "2025-07-16T08:31:25.815624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retriever_node(s: AgentState):\n",
    "    \"\"\"\n",
    "    Retrieves relevant documents based on the user's query using Chroma vector store.\n",
    "    Embeds the query and performs vector similarity search to populate AgentState.retrieved_docs.\n",
    "    \"\"\"\n",
    "\n",
    "    if not s.query:\n",
    "        raise ValueError(\"‚ùå Query is not set. Please provide a valid query.\")\n",
    "\n",
    "    # Step 1: Embed the query using Google Generative AI Embeddings\n",
    "    query_embedding = embeddings.embed_query(s.query)\n",
    "\n",
    "    # Step 2: Load existing Chroma vector store\n",
    "    vector_store = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "\n",
    "    # Step 3: Perform similarity search\n",
    "    try:\n",
    "        results = vector_store.similarity_search_by_vector(query_embedding, k=5)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"‚ö†Ô∏è Error during similarity search: {e}\")\n",
    "\n",
    "    # Step 4: Handle empty results gracefully\n",
    "    if not results:\n",
    "        print(\"‚ö†Ô∏è No relevant documents found for this query.\")\n",
    "        s.retrieved_docs = [Document(page_content=\"No relevant content found.\", metadata={\"source\": \"None\"})]\n",
    "    else:\n",
    "        s.retrieved_docs = results\n",
    "        print(f\"‚úÖ Retrieved {len(s.retrieved_docs)} relevant documents.\")\n",
    "\n",
    "    return s\n"
   ],
   "id": "4bf3efc270fb8a1e",
   "outputs": [],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T08:31:25.838226Z",
     "start_time": "2025-07-16T08:31:25.831187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def synthesis_node(s: AgentState):\n",
    "    \"\"\"Uses Gemini to generate an answer from retrieved documents.\"\"\"\n",
    "\n",
    "    if not s.retrieved_docs or not s.query:\n",
    "        raise ValueError(\"‚ùå Missing retrieved documents or query.\")\n",
    "\n",
    "    # Step 1: Combine retrieved chunks into a single context\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in s.retrieved_docs])\n",
    "\n",
    "    # Step 2: Format the prompt\n",
    "    prompt = f\"\"\"You are a helpful assistant.\n",
    "Answer the question using ONLY the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {s.query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Step 3: Call Gemini using .invoke()\n",
    "    s.answer = llm.invoke(prompt)\n",
    "\n",
    "    print(\"‚úÖ Answer generated.\")\n",
    "    return s\n"
   ],
   "id": "6dcf70ad1471680d",
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T08:31:25.851417Z",
     "start_time": "2025-07-16T08:31:25.846926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def output_node(s: AgentState):\n",
    "    \"\"\"Outputs the final answer to the user.\"\"\"\n",
    "    if not s.answer:\n",
    "        raise ValueError(\"No answer generated. Please check the previous steps.\")\n",
    "\n",
    "    print(f\"\\nüí° Final Answer:\\n{s.answer}\")\n",
    "    return s  # ‚úÖ Must return updated state, not END\n"
   ],
   "id": "caf9302d69546fc4",
   "outputs": [],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T08:31:25.870446Z",
     "start_time": "2025-07-16T08:31:25.860958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the graph\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"input\", input_node)\n",
    "graph.add_node(\"retriever\", retriever_node)\n",
    "graph.add_node(\"synthesis\", synthesis_node)\n",
    "graph.add_node(\"output\", output_node)\n",
    "\n",
    "# Define transitions\n",
    "graph.add_edge(\"input\", \"retriever\")\n",
    "graph.add_edge(\"retriever\", \"synthesis\")\n",
    "graph.add_edge(\"synthesis\", \"output\")\n",
    "graph.add_edge(\"output\", END)\n",
    "\n",
    "# Set entry and exit points\n",
    "graph.set_entry_point(\"input\")\n",
    "graph.set_finish_point(\"output\")\n",
    "\n",
    "# Compile the app\n",
    "app = graph.compile()"
   ],
   "id": "90ef18c1ba79a076",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T08:34:10.645101Z",
     "start_time": "2025-07-16T08:33:24.567753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "initial_state = {\n",
    "    \"query\": \"are women safe in public transport like taxi ?\"\n",
    "}\n",
    "\n",
    "# Run the app\n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "# Print answer and source snippets\n",
    "print(\"\\n‚úÖ Final Answer:\", final_state[\"answer\"])\n",
    "\n",
    "print(\"\\nüìö Retrieved Docs Preview:\")\n",
    "for i, doc in enumerate(final_state[\"retrieved_docs\"]):\n",
    "    print(f\"Doc {i+1} ‚Äî Source: {doc.metadata.get('source', 'N/A')}\")\n",
    "    print(doc.page_content[:200], \"...\\n\")\n"
   ],
   "id": "9fc749340e60f76c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 5 relevant documents.\n",
      "‚úÖ Answer generated.\n",
      "\n",
      "üí° Final Answer:\n",
      "content='Longer waiting periods, erratic police and safety officer presence, frequent muggings at bus and rail stations, and threatening experiences (including exhibitionism) from male commuters and drivers in minibus taxis.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash-latest', 'safety_ratings': []} id='run--786c16c0-a8e7-4a02-a45d-1df642282106-0' usage_metadata={'input_tokens': 569, 'output_tokens': 38, 'total_tokens': 607, 'input_token_details': {'cache_read': 0}}\n",
      "\n",
      "‚úÖ Final Answer: content='Longer waiting periods, erratic police and safety officer presence, frequent muggings at bus and rail stations, and threatening experiences (including exhibitionism) from male commuters and drivers in minibus taxis.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash-latest', 'safety_ratings': []} id='run--786c16c0-a8e7-4a02-a45d-1df642282106-0' usage_metadata={'input_tokens': 569, 'output_tokens': 38, 'total_tokens': 607, 'input_token_details': {'cache_read': 0}}\n",
      "\n",
      "üìö Retrieved Docs Preview:\n",
      "Doc 1 ‚Äî Source: data\\sample1.pdf\n",
      "having to commute with minibus taxis, each participant was often more concerned about their \n",
      "safety on public bus and rail services ‚Äì citing longer waiting periods, erratic presence of police and \n",
      "oth ...\n",
      "\n",
      "Doc 2 ‚Äî Source: data\\sample1.pdf\n",
      "having to commute with minibus taxis, each participant was often more concerned about their \n",
      "safety on public bus and rail services ‚Äì citing longer waiting periods, erratic presence of police and \n",
      "oth ...\n",
      "\n",
      "Doc 3 ‚Äî Source: data\\sample1.pdf\n",
      "having to commute with minibus taxis, each participant was often more concerned about their \n",
      "safety on public bus and rail services ‚Äì citing longer waiting periods, erratic presence of police and \n",
      "oth ...\n",
      "\n",
      "Doc 4 ‚Äî Source: data\\sample1.pdf\n",
      "having to commute with minibus taxis, each participant was often more concerned about their \n",
      "safety on public bus and rail services ‚Äì citing longer waiting periods, erratic presence of police and \n",
      "oth ...\n",
      "\n",
      "Doc 5 ‚Äî Source: data\\sample1.pdf\n",
      "having to commute with minibus taxis, each participant was often more concerned about their \n",
      "safety on public bus and rail services ‚Äì citing longer waiting periods, erratic presence of police and \n",
      "oth ...\n",
      "\n"
     ]
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f8e8d1c16ce561e"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
